{"name":"fb-caffe-exts","tagline":"Some handy utility libraries and tools for the Caffe deep learning framework.","body":"<div id=\"table-of-contents\">\r\n<h2>Table of Contents</h2>\r\n<div id=\"text-table-of-contents\">\r\n<ul>\r\n<li><a href=\"#orgheadline6\">1. <code>fb-caffe-exts</code></a>\r\n<ul>\r\n<li><a href=\"#orgheadline1\">1.1. <code>predictor/</code></a></li>\r\n<li><a href=\"#orgheadline2\">1.2. <code>torch2caffe/</code></a></li>\r\n<li><a href=\"#orgheadline3\">1.3. <code>conversions/</code></a></li>\r\n<li><a href=\"#orgheadline4\">1.4. Building and Installing</a></li>\r\n<li><a href=\"#orgheadline5\">1.5. Contact</a></li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</div>\r\n</div>\r\n\r\n# `fb-caffe-exts`<a id=\"orgheadline6\"></a>\r\n\r\n`fb-caffe-exts` is a collection of extensions developed at FB while using Caffe\r\nin (mainly) production scenarios.\r\n\r\n## `predictor/`<a id=\"orgheadline1\"></a>\r\n\r\nA simple C++ library that wraps the common pattern of running a `caffe::Net` in\r\nmultiple threads while sharing weights. It also provides a slightly more\r\nconvenient usage API for the inference case.\r\n\r\n    #include \"caffe/predictor/Predictor.h\"\r\n    \r\n    // In your setup phase\r\n    predictor_ = folly::make_unique<caffe::fb::Predictor>(FLAGS_prototxt_path,\r\n                                                          FLAGS_weights_path);\r\n    \r\n    // When calling in a worker thread\r\n    static thread_local caffe::Blob<float> input_blob;\r\n    input_blob.set_cpu_data(input_data); // avoid the copy.\r\n    const auto& output_blobs = predictor_->forward({&input_blob});\r\n    return output_blobs[FLAGS_output_layer_name];\r\n\r\nOf note is the `predictor/Optimize.{h,cpp}`, which optimizes memory\r\nusage by automatically reusing the intermediate activations when this is safe.\r\nThis reduces the amount of memory required for intermediate activations by\r\naround 50% for AlexNet-style models, and around 75% for GoogLeNet-style\r\nmodels.\r\n\r\nWe can plot each set of activations in the topological ordering of the network,\r\nwith a unique color for each reused activation buffer, with the height of the\r\nblob proportional to the size of the buffer.\r\n\r\nFor example, in an AlexNet-like model, the allocation looks like\r\n\r\n\r\n![CaffeNet](https://raw.githubusercontent.com/facebook/fb-caffe-exts/master/doc/caffenet.png)\r\n\r\nA corresponding allocation for GoogLeNet looks like\r\n\r\n![GoogLeNet](https://raw.githubusercontent.com/facebook/fb-caffe-exts/master/doc/googlenet.png)\r\n\r\nThe idea is essentially linear scan register allocation. We\r\n\r\n-   compute a set of \"live ranges\" for each `caffe::SyncedMemory` (due to sharing,\r\n    we can't do this at a `caffe::Blob` level)\r\n-   compute a set of live intervals, and schedule each `caffe::SyncedMemory` in a\r\n    non-overlapping fashion onto each live interval\r\n-   allocate a canonical `caffe::SyncedMemory` buffer for each live interval\r\n-   Update the blob internal pointers to point to the canonical buffer\r\n\r\nDepending on the model, the buffer reuse can also lead to some non-trivial\r\nperformance improvements at inference time.\r\n\r\nTo enable this just pass `Predictor::Optimization::MEMORY` to the `Predictor`\r\nconstructor.\r\n\r\n## `torch2caffe/`<a id=\"orgheadline2\"></a>\r\n\r\nA library for converting pre-trained Torch models to the equivalent Caffe models.\r\n\r\n`torch_layers.lua` describes the set of layers that we can automatically\r\nconvert, and `test.lua` shows some examples of more complex models being\r\nconverted end to end.\r\n\r\nFor example, complex CNNs ([GoogLeNet](http://arxiv.org/abs/1409.4842), etc), deep LSTMs (created in [nngraph](https://github.com/torch/nngraph)),\r\nmodels with tricky parallel/split connectivity structures ([Natural Language\r\nProcessing (almost) from Scratch](http://arxiv.org/abs/1103.0398)), etc.\r\n\r\nThis can be invoked as\r\n\r\n    ∴ th torch2caffe/torch2caffe.lua --help\r\n    --input (default \"\") Input model file\r\n    --preprocessing (default \"\") Preprocess the model\r\n    --prototxt (default \"\") Output prototxt model file\r\n    --caffemodel (default \"\") Output model weights file\r\n    --format (default \"lua\") Format: lua | luathrift\r\n    --input-tensor (default \"\") (Optional) Predefined input tensor\r\n    --verify (default \"\") (Optional) Verify existing\r\n    <input_dims...> (number) Input dimensions (e.g. 10N x 3C x 227H x 227W)\r\n\r\nThis works by\r\n\r\n-   (optionally) preprocessing the model provided in `--input`, (folding\r\n    BatchNormalization layers into the preceding layer, etc),\r\n-   walking the Torch module graph of the model provide in `--input`,\r\n-   converting it to the equivalent Caffe module graph,\r\n-   copying the weights into the Caffe model,\r\n-   Running some test inputs (of size `input_dims...`) through both models and\r\n    verifying the outputs are identical.\r\n\r\n## `conversions/`<a id=\"orgheadline3\"></a>\r\n\r\nA simple CLI tool for running some simple Caffe network transformations.\r\n\r\n    ∴ python conversions.py vision --help\r\n    Usage: conversions.py vision [OPTIONS]\r\n    \r\n    Options:\r\n      --prototxt TEXT           [required]\r\n      --caffemodel TEXT         [required]\r\n      --output-prototxt TEXT    [required]\r\n      --output-caffemodel TEXT  [required]\r\n      --help                    Show this message and exit.\r\n\r\nThe main usage at the moment is automating the [Net Surgery](https://github.com/BVLC/caffe/blob/master/examples/net_surgery.ipynb) notebook.\r\n\r\n## Building and Installing<a id=\"orgheadline4\"></a>\r\n\r\nAs you might expect, this library depends on an up-to-date [BVLC Caffe](http://caffe.berkeleyvision.org/) installation.\r\n\r\nThe additional dependencies are\r\n\r\n-   The C++ libraries require [folly](https://github.com/facebook/folly).\r\n-   The Python `conversions` libraries requires [click](http://click.pocoo.org/5/).\r\n\r\nYou can drop the C++ components into an existing Caffe installation. We'll\r\nupdate the repo with an example modification to an existing `Makefile.config`\r\nand a `CMake` based solution.\r\n\r\n## Contact<a id=\"orgheadline5\"></a>\r\n\r\nFeel free to open issues on this repo for requests/bugs, or contact [Andrew\r\nTulloch](tulloch@fb.com) directly.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}